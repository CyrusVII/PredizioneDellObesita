{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7ed0dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\filip\\AppData\\Local\\Temp\\ipykernel_2452\\2877727107.py:34: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df.replace({'yes': True, 'no': False}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Obesity Prediction - Preprocessing Pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# === 1. Caricamento dei dati ===\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# === 2. Pulizia valori nulli ===\n",
    "train_df.dropna(inplace=True)\n",
    "test_df.dropna(inplace=True)\n",
    "\n",
    "# === 3. Mappatura della colonna target 'NObeyesdad' ===\n",
    "weight_map = {\n",
    "    'Normal_Weight': 0,\n",
    "    'Insufficient_Weight': -1,\n",
    "    'Overweight_Level_I': 1,\n",
    "    'Overweight_Level_II': 2,\n",
    "    'Obesity_Type_I': 3,\n",
    "    'Obesity_Type_II': 4,\n",
    "    'Obesity_Type_III': 5\n",
    "}\n",
    "train_df['NObeyesdad'] = train_df['NObeyesdad'].map(weight_map)\n",
    "\n",
    "# === 4. Encoding yes/no â†’ True/False ===\n",
    "for df in [train_df, test_df]:\n",
    "    df.replace({'yes': True, 'no': False}, inplace=True)\n",
    "\n",
    "# === 5. Label Encoding delle colonne categoriche (esclusa la colonna target) ===\n",
    "categorical_cols = train_df.select_dtypes(include='object').columns\n",
    "label_encoders = {}\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    \n",
    "    # Fit su dati combinati per evitare problemi con categorie nuove\n",
    "    combined = pd.concat([train_df[col], test_df[col]], axis=0).astype(str)\n",
    "    le.fit(combined)\n",
    "    \n",
    "    train_df[col] = le.transform(train_df[col].astype(str))\n",
    "    test_df[col] = le.transform(test_df[col].astype(str))\n",
    "    \n",
    "    label_encoders[col] = le\n",
    "\n",
    "# === 6. Separazione input e target ===\n",
    "X = train_df.drop(columns=['id', 'NObeyesdad'])  # Rimuove id e target\n",
    "y = train_df['NObeyesdad']\n",
    "\n",
    "# === 7. Train/validation split ===\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "290ab824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 7. Feature selection (opzionale, basata su VIF e p-value) ===\n",
    "def calculate_vif(X):\n",
    "    # Assicura solo colonne numeriche e converte bool in int\n",
    "    X_numeric = X.select_dtypes(include=[np.number, 'bool']).copy()\n",
    "    X_numeric = X_numeric.astype(float)\n",
    "    \n",
    "    # Rimuove eventuali infiniti\n",
    "    X_numeric.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    X_numeric.dropna(inplace=True)\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'feature': X_numeric.columns,\n",
    "        'VIF': [variance_inflation_factor(X_numeric.values, i) for i in range(X_numeric.shape[1])]\n",
    "    })\n",
    "\n",
    "def calculate_pvalues(X, y):\n",
    "    X_const = sm.add_constant(X)\n",
    "    model = sm.OLS(y, X_const).fit()\n",
    "    return model.pvalues[1:]  # exclude intercept\n",
    "\n",
    "def feature_selection(X, y, vif_threshold=10, pval_threshold=0.05):\n",
    "    while True:\n",
    "        vif = calculate_vif(X)\n",
    "        pvals = calculate_pvalues(X, y)\n",
    "\n",
    "        drop_cols = [\n",
    "            col for col in X.columns\n",
    "            if vif[vif.feature == col]['VIF'].values[0] > vif_threshold or pvals[col] > pval_threshold\n",
    "        ]\n",
    "\n",
    "        if not drop_cols:\n",
    "            break\n",
    "\n",
    "        print(f\"Rimosse feature: {drop_cols}\")\n",
    "        X = X.drop(columns=drop_cols)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daed2306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender                              int32\n",
      "Age                               float64\n",
      "Height                            float64\n",
      "Weight                            float64\n",
      "family_history_with_overweight       bool\n",
      "FAVC                                 bool\n",
      "FCVC                              float64\n",
      "NCP                               float64\n",
      "CAEC                                int32\n",
      "SMOKE                                bool\n",
      "CH2O                              float64\n",
      "SCC                                  bool\n",
      "FAF                               float64\n",
      "TUE                               float64\n",
      "CALC                                int32\n",
      "MTRANS                              int32\n",
      "dtype: object\n",
      "Gender                            0\n",
      "Age                               0\n",
      "Height                            0\n",
      "Weight                            0\n",
      "family_history_with_overweight    0\n",
      "FAVC                              0\n",
      "FCVC                              0\n",
      "NCP                               0\n",
      "CAEC                              0\n",
      "SMOKE                             0\n",
      "CH2O                              0\n",
      "SCC                               0\n",
      "FAF                               0\n",
      "TUE                               0\n",
      "CALC                              0\n",
      "MTRANS                            0\n",
      "dtype: int64\n",
      "Gender    True\n",
      "Age       True\n",
      "Height    True\n",
      "Weight    True\n",
      "FCVC      True\n",
      "NCP       True\n",
      "CAEC      True\n",
      "CH2O      True\n",
      "FAF       True\n",
      "TUE       True\n",
      "CALC      True\n",
      "MTRANS    True\n",
      "dtype: bool\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Pandas data cast to numpy dtype of object. Check input data with np.asarray(data).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(X\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39msum())\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39misfinite(X\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[np\u001b[38;5;241m.\u001b[39mnumber]))\u001b[38;5;241m.\u001b[39mall())\n\u001b[1;32m----> 5\u001b[0m X_train_selected \u001b[38;5;241m=\u001b[39m feature_selection(X_train\u001b[38;5;241m.\u001b[39mcopy(), y_train)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# === 8. Modello ===\u001b[39;00m\n\u001b[0;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "Cell \u001b[1;32mIn[5], line 24\u001b[0m, in \u001b[0;36mfeature_selection\u001b[1;34m(X, y, vif_threshold, pval_threshold)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     23\u001b[0m     vif \u001b[38;5;241m=\u001b[39m calculate_vif(X)\n\u001b[1;32m---> 24\u001b[0m     pvals \u001b[38;5;241m=\u001b[39m calculate_pvalues(X, y)\n\u001b[0;32m     26\u001b[0m     drop_cols \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     27\u001b[0m         col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m X\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m     28\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m vif[vif\u001b[38;5;241m.\u001b[39mfeature \u001b[38;5;241m==\u001b[39m col][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVIF\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m vif_threshold \u001b[38;5;129;01mor\u001b[39;00m pvals[col] \u001b[38;5;241m>\u001b[39m pval_threshold\n\u001b[0;32m     29\u001b[0m     ]\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m drop_cols:\n",
      "Cell \u001b[1;32mIn[5], line 18\u001b[0m, in \u001b[0;36mcalculate_pvalues\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_pvalues\u001b[39m(X, y):\n\u001b[0;32m     17\u001b[0m     X_const \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39madd_constant(X)\n\u001b[1;32m---> 18\u001b[0m     model \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39mOLS(y, X_const)\u001b[38;5;241m.\u001b[39mfit()\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mpvalues[\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[1;32mc:\\Users\\filip\\anaconda3\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:924\u001b[0m, in \u001b[0;36mOLS.__init__\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    921\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeights are not supported in OLS and will be ignored\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    922\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn exception will be raised in the next version.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    923\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg, ValueWarning)\n\u001b[1;32m--> 924\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(endog, exog, missing\u001b[38;5;241m=\u001b[39mmissing,\n\u001b[0;32m    925\u001b[0m                           hasconst\u001b[38;5;241m=\u001b[39mhasconst, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    926\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_keys:\n\u001b[0;32m    927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_keys\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\filip\\anaconda3\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:749\u001b[0m, in \u001b[0;36mWLS.__init__\u001b[1;34m(self, endog, exog, weights, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     weights \u001b[38;5;241m=\u001b[39m weights\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m--> 749\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(endog, exog, missing\u001b[38;5;241m=\u001b[39mmissing,\n\u001b[0;32m    750\u001b[0m                           weights\u001b[38;5;241m=\u001b[39mweights, hasconst\u001b[38;5;241m=\u001b[39mhasconst, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    751\u001b[0m nobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    752\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights\n",
      "File \u001b[1;32mc:\\Users\\filip\\anaconda3\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:203\u001b[0m, in \u001b[0;36mRegressionModel.__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 203\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(endog, exog, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpinv_wexog: Float64Array \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_attr\u001b[38;5;241m.\u001b[39mextend([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpinv_wexog\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwendog\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwexog\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\filip\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\model.py:270\u001b[0m, in \u001b[0;36mLikelihoodModel.__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 270\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(endog, exog, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize()\n",
      "File \u001b[1;32mc:\\Users\\filip\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\model.py:95\u001b[0m, in \u001b[0;36mModel.__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m missing \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     94\u001b[0m hasconst \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhasconst\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m---> 95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_data(endog, exog, missing, hasconst,\n\u001b[0;32m     96\u001b[0m                               \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_constant \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mk_constant\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mexog\n",
      "File \u001b[1;32mc:\\Users\\filip\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\model.py:135\u001b[0m, in \u001b[0;36mModel._handle_data\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_handle_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, missing, hasconst, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 135\u001b[0m     data \u001b[38;5;241m=\u001b[39m handle_data(endog, exog, missing, hasconst, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;66;03m# kwargs arrays could have changed, easier to just attach here\u001b[39;00m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m kwargs:\n",
      "File \u001b[1;32mc:\\Users\\filip\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\data.py:675\u001b[0m, in \u001b[0;36mhandle_data\u001b[1;34m(endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    672\u001b[0m     exog \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(exog)\n\u001b[0;32m    674\u001b[0m klass \u001b[38;5;241m=\u001b[39m handle_data_class_factory(endog, exog)\n\u001b[1;32m--> 675\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m klass(endog, exog\u001b[38;5;241m=\u001b[39mexog, missing\u001b[38;5;241m=\u001b[39mmissing, hasconst\u001b[38;5;241m=\u001b[39mhasconst,\n\u001b[0;32m    676\u001b[0m              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\filip\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\data.py:84\u001b[0m, in \u001b[0;36mModelData.__init__\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_endog \u001b[38;5;241m=\u001b[39m endog\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_exog \u001b[38;5;241m=\u001b[39m exog\n\u001b[1;32m---> 84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendog, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_endog_exog(endog, exog)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconst_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_constant \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\filip\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\data.py:509\u001b[0m, in \u001b[0;36mPandasData._convert_endog_exog\u001b[1;34m(self, endog, exog)\u001b[0m\n\u001b[0;32m    507\u001b[0m exog \u001b[38;5;241m=\u001b[39m exog \u001b[38;5;28;01mif\u001b[39;00m exog \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(exog)\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m endog\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m exog \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m exog\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m--> 509\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPandas data cast to numpy dtype of object. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    510\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheck input data with np.asarray(data).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_convert_endog_exog(endog, exog)\n",
      "\u001b[1;31mValueError\u001b[0m: Pandas data cast to numpy dtype of object. Check input data with np.asarray(data)."
     ]
    }
   ],
   "source": [
    "print(X.dtypes)\n",
    "print(X.isnull().sum())\n",
    "print(np.isfinite(X.select_dtypes(include=[np.number])).all())\n",
    "\n",
    "X_train_selected = feature_selection(X_train.copy(), y_train)\n",
    "\n",
    "# === 8. Modello ===\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train_selected, y_train)\n",
    "\n",
    "# === 9. Preparazione del test set ===\n",
    "X_test = test_df.drop(columns=['id', 'NObeyesdad'], errors='ignore')  # Rimuovi 'id' e 'NObeyesdad' se presenti\n",
    "X_test_selected = X_test[X_train_selected.columns]  # Allinea le colonne con quelle selezionate nel train\n",
    "\n",
    "predictions = model.predict(X_test_selected)\n",
    "\n",
    "# Inverti l'encoding per avere le etichette leggibili\n",
    "pred_labels = le.inverse_transform(predictions)# === 7. Feature selection (opzionale, basata su VIF e p-value) ===\n",
    "def calculate_vif(X):\n",
    "    # Rimuovi colonne non numeriche\n",
    "    X = X.select_dtypes(include=[np.number])\n",
    "    # Gestisci valori mancanti\n",
    "    X = X.fillna(0)  # Sostituisci NaN con 0 (o usa un'altra strategia)\n",
    "    return pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'VIF': [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    })\n",
    "\n",
    "def calculate_pvalues(X, y):\n",
    "    X_const = sm.add_constant(X)\n",
    "    model = sm.OLS(y, X_const).fit()\n",
    "    return model.pvalues[1:]  # exclude intercept\n",
    "\n",
    "def feature_selection(X, y, vif_threshold=10, pval_threshold=0.05):\n",
    "    # Rimuovi colonne non numeriche\n",
    "    X = X.select_dtypes(include=[np.number])\n",
    "    # Gestisci valori mancanti\n",
    "    X = X.fillna(0)  # Sostituisci NaN con 0 (o usa un'altra strategia)\n",
    "    \n",
    "    while True:\n",
    "        vif = calculate_vif(X)\n",
    "        pvals = calculate_pvalues(X, y)\n",
    "\n",
    "        drop_cols = [\n",
    "            col for col in X.columns\n",
    "            if vif[vif.feature == col]['VIF'].values[0] > vif_threshold or pvals[col] > pval_threshold\n",
    "        ]\n",
    "\n",
    "        if not drop_cols:\n",
    "            break\n",
    "\n",
    "        print(f\"Rimosse feature: {drop_cols}\")\n",
    "        X = X.drop(columns=drop_cols)\n",
    "\n",
    "    return X\n",
    "\n",
    "# Applica la funzione di selezione delle feature\n",
    "X_train_selected = feature_selection(X_train.copy(), y_train)\n",
    "\n",
    "# Crea un DataFrame con gli ID e le predizioni\n",
    "output = test_df[['id']].copy()\n",
    "output['Predicted_Obesity_Level'] = pred_labels\n",
    "\n",
    "# Mostra le prime 10 predizioni\n",
    "print(\"ðŸ“Š Prime 10 predizioni sul test set:\")\n",
    "print(output.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
